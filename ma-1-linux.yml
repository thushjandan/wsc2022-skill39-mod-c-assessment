---
- name: MARKING - Linux
  hosts: linux,localhost
  any_errors_fatal: false
  tasks:
    ## Linux: Hostname
    - name: "Linux: Hostname"
      debug:
        var: ansible_hostname
      when: 
        - "'linux' in group_names"
      tags:
        - c1_1
      
    - name: Assert Hostname
      assert:
        that: "hostname == ansible_hostname"
        success_msg: Hostname is correctly configured
        fail_msg: "Hostname doesn't match. Configured: {{ ansible_hostname }}. Expected: {{ hostname }}"
        quiet: true
      ignore_errors: true
      when: 
        - "'linux' in group_names"
      tags:
        - c1_1

    - pause:
        prompt: "Please mark now aspect - Linux: Hostname"
      tags:
        - c1_1

    ## nftables: Packet filtering
    - name: "Get iptables rules"
      shell: "nft list ruleset ; printf ' \n \n \n'"
      ignore_errors: true
      changed_when: false
      register: out_packet_filtering
      when: 
        - "'linux' in group_names"
      tags:
        - c1_2

    - name: "nftables: Packet filtering"
      debug:
        var: out_packet_filtering.stdout
      when: 
        - "'linux' in group_names"
      tags:
        - c1_2

    - pause:
        prompt: "Please mark now aspect - nftables: Packet filtering"
      tags:
        - c1_2

    # nftables: trusted list
    - name: "Get trusted list in nftables"
      shell: "cat /etc/nftables.conf"
      register: out_packet_filtering_trusted_list
      when:
        - "'linux' in group_names"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_3

    - name: "nftables: trusted list"
      debug:
        var: out_packet_filtering_trusted_list.stdout
      when: 
        - "'linux' in group_names"
      tags:
        - c1_3

    - pause:
        prompt: "Please mark now aspect - nftables: trusted list"
      tags:
        - c1_3

    # nftables: Rules persist across reboots
    - name: Pick random node for rebooting
      set_fact:
        nftables_selected_host: "{{ groups.linux | random }}"
      run_once: true
      tags:
        - c1_4

    - debug:
        msg: "Host {{ nftables_selected_host }} has been chosen to reboot."
      run_once: true
      tags:
        - c1_4

    - name: Reboot a random LIN host
      reboot:
        reboot_timeout: 180
      when: 'inventory_hostname == nftables_selected_host'
      ignore_errors: true
      changed_when: false
      tags:
        - c1_4
    
    - name: "Get nftables rules of LIN4"
      shell: "nft list ruleset ; printf ' \n \n \n'"
      register: out_packet_filtering_lin
      when: 'inventory_hostname == nftables_selected_host'
      ignore_errors: true
      changed_when: false
      tags:
        - c1_4

    - name: "nftables: Rules persist across reboots"
      debug:
        var: out_packet_filtering_lin.stdout
      when: 'inventory_hostname == nftables_selected_host'
      tags:
        - c1_4

    - pause:
        prompt: "Please mark now aspect - nftables: Rules persist across reboots"
      tags:
        - c1_4
    
    ## DNS: Primary/Master DNS server
    - name: "Try zone transfer from primary on all DNS servers"
      shell: "dig @10.22.0.2 applix.com AXFR +noall +comments +timeout=2 +tries=1"
      register: dns_primary_transfer
      when: 
        - "'dns' in group_names"
        - "inventory_hostname != groups.dns[0]"
      changed_when: false
      ignore_errors: true
      tags:
        - c1_5

    - name: "DNS: Primary/Master DNS server"
      debug:
        var: dns_primary_transfer.stdout
      when: 
        - "'dns' in group_names"
        - "inventory_hostname != groups.dns[0]"
      tags:
        - c1_5

    - pause:
        prompt: "Please mark now aspect - DNS: Primary/Master DNS server"
      tags:
        - c1_5

    ## DNS: Secondary/Slave DNS servers
    - name: "Try zone transfer from secondary"
      shell: "! dig @10.22.0.5 applix.com AXFR +timeout=2 +tries=1"
      register: dns_secondary_transfer
      when: 
        - "'dns' in group_names"
        - "inventory_hostname != (groups.dns|last)"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_6
    
    - name: "Execute dig towards secondary"
      shell: "dig @{{ hostvars[item]['ansible_host'] }} applix.com SOA +noall +comments +timeout=5 +tries=1"
      register: dns_secondary_dig
      loop: "{{ (groups.dns[1:]|list) }}"
      loop_control:
        label: "{{ item }}"
      delegate_to: localhost
      run_once: true
      ignore_errors: true
      changed_when: false
      tags:
        - c1_6

    - name: "DNS: Secondary/Slave DNS servers - No zone transfers between slaves allowed"
      debug:
        var: dns_secondary_transfer.stdout
      when: 
        - "'dns' in group_names"
        - "inventory_hostname != (groups.dns|last)"
      tags:
        - c1_6

    - name: "DNS: Secondary/Slave DNS servers - Slaves answer DNS queries"
      debug:
        msg: "{{ item.stdout }}"
      delegate_to: localhost
      loop: "{{ dns_secondary_dig.results }}"
      loop_control:
        label: "{{ item.cmd }}"
      run_once: true
      tags:
        - c1_6

    - pause:
        prompt: "Please mark now aspect - Secondary/Slave DNS servers"
      tags:
        - c1_6
    
    ## DNS: A records in zone applix.com
    - name: "Resolve all DNS entries from hosts file"
      shell: "dig @10.22.0.2 {{ hostvars[item]['hostname']|default(hostvars[item]['inventory_hostname']) }}.applix.com +noall +answer +timeout=3 +tries=1"
      register: dns_a_entries
      run_once: true
      delegate_to: localhost
      loop: "{{ groups.all }}"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_7

    - name: "Assert if A records in zone applix.com are correct"
      assert:
        that: "{{ item.stdout.split('\t')|last == hostvars[item.item]['ansible_host'] }}"
        success_msg: "A record for {{ hostvars[item.item]['hostname']|default(hostvars[item]['inventory_hostname']) }}.applix.com is correctly configured"
        fail_msg: "A record for {{ hostvars[item.item]['hostname']|default(hostvars[item]['inventory_hostname']) }}.applix.com doesn't match. Configured: {{ item.stdout.split('\t')|last }}. Expected: {{ hostvars[item.item]['ansible_host'] }}"
        quiet: true
      ignore_errors: true
      delegate_to: localhost
      loop: "{{ dns_a_entries.results }}"
      loop_control:
        label: "{{ item.cmd }}"
      run_once: true
      tags:
        - c1_7

    - name: "DNS: A records in zone applix.com"
      debug:
        msg: "{{ item.stdout|replace('\t',' ') }}"
      delegate_to: localhost
      loop: "{{ dns_a_entries.results }}"
      loop_control:
        label: "{{ item.cmd }}"
      run_once: true
      tags:
        - c1_7
  
    - pause:
        prompt: "Please mark now aspect - A records in zone applix.com"
      tags:
        - c1_7

    ## DNS: intranet.applix.com resolves to 10.22.0.51
    - name: "Resolve intranet.applix.com"
      shell: "dig @10.22.0.2 intranet.applix.com +noall +answer +timeout=5 +tries=1"
      register: dns_intranet_a_entry
      run_once: true
      delegate_to: localhost
      ignore_errors: true
      changed_when: false
      tags:
        - c1_8
      
    - name: "Assert if intranet.applix.com resolves to 10.22.0.51"
      assert:
        that: "{{ dns_intranet_a_entry.stdout.split('\t')|last == '10.22.0.51' }}"
        success_msg: "intranet.applix.com resolves correctly to 10.22.0.51"
        fail_msg: "intranet.applix.com doesn't resolve correctly. Currently resolves to: {{ dns_intranet_a_entry.stdout.split('\t')|last }}. Expected: 10.22.0.51"
        quiet: true
      ignore_errors: true
      delegate_to: localhost
      run_once: true
      tags:
        - c1_8

    - name: "DNS: intranet.applix.com resolves to 10.22.0.51"
      debug:
        msg: "{{ dns_intranet_a_entry.stdout|replace('\t',' ') }}"
      delegate_to: localhost
      run_once: true
      tags:
        - c1_8

    - pause:
        prompt: "Please mark now aspect - intranet.applix.com resolves to 10.22.0.51"
      tags:
        - c1_8
    
    ## DNS: DNS server configured on Linux servers
    - name: "Check if primary nameserver is configured on linux hosts"
      shell: "dig applix.com SOA +noall +stats +timeout=5 +tries=1 | grep SERVER"
      register: dns_client_primary
      ignore_errors: true
      changed_when: false
      tags:
        - c1_9

    - name: "Check if backup nameserver is configured on linux hosts"
      shell: "cat /etc/resolv.conf | grep nameserver"
      register: dns_client_secondaries
      ignore_errors: true
      changed_when: false
      tags:
        - c1_9

    - name: "DNS: DNS server configured on Linux servers - Check if primary nameserver is configured"
      assert:
        that: "{{ '10.22.0.2' in dns_client_primary.stdout }}"
        success_msg: "10.22.0.2 is correctly configured as primary nameserver"
        fail_msg: "10.22.0.2 is not the primary server for {{ inventory_hostname }}. Configured: {{ dns_client_primary.stdout.split('#')|first }}. Expected: 10.22.0.2"
        quiet: true
      ignore_errors: true
      tags:
        - c1_9

    - name: "DNS: DNS server configured on Linux servers - Check if backup nameservers are configured"
      assert:
        that:
          - "{{ '10.22.0.3' in dns_client_secondaries.stdout }}"
          - "{{ '10.22.0.4' in dns_client_secondaries.stdout }}"
          - "{{ '10.22.0.5' in dns_client_secondaries.stdout }}"
        success_msg: "10.22.0.3, 10.22.0.4 & 10.22.0.5 are correctly configured as backup nameserver"
        fail_msg: "Not all backup nameserver are configured for {{ inventory_hostname }}. Configured:\n{{ dns_client_secondaries.stdout }}\nExpected: 10.22.0.3, 10.22.0.4 & 10.22.0.5"
        quiet: true
      ignore_errors: true
      tags:
        - c1_9

    - name: "DNS server configured on Linux servers"
      debug:
        msg: |-
          {{ dns_client_primary.cmd }}
          {{ dns_client_primary.stdout }}
          
          {{ dns_client_secondaries.cmd }}
          {{ dns_client_secondaries.stdout }}
      tags:
        - c1_9

    - pause:
        prompt: "Please mark now aspect - DNS server configured on Linux servers"
      tags:
        - c1_9

    ## DNS: DNS suffix applix.com is configured
    - name: "Check if DNS suffix is configured on linux hosts"
      shell: "cat /etc/resolv.conf | { grep -E 'search|domain' || true; }"
      register: dns_client_suffix
      ignore_errors: true
      changed_when: false
      tags:
        - c1_10

    - name: "Assert if DNS suffix applix.com is configured"
      assert:
        that:
          - "{{ 'applix.com' in (dns_client_suffix.stdout|lower) }}"
        success_msg: "applix.com is correctly configured as DNS suffix"
        fail_msg: "DNS suffix is not correctly configured for {{ inventory_hostname }}. Configured: {{ dns_client_suffix.stdout }}. Expected: applix.com"
        quiet: true
      ignore_errors: true
      tags:
        - c1_10

    - name: "DNS suffix applix.com is configured"
      debug:
        msg: |-
          {{ dns_client_suffix.cmd }}
          {{ dns_client_suffix.stdout }}
      tags:
        - c1_10

    - pause:
        prompt: "Please mark now aspect - DNS suffix applix.com is configured"
      tags:
        - c1_10
    
    ## Web: Webserver listen on port defined in the variable webport
    - name: "Test if webserver is listening on webport"
      ansible.builtin.uri:
        url: "http://{{ hostvars[inventory_hostname]['ansible_host'] }}:{{ webport }}"
        return_content: yes
      register: web_server_listen
      when: "inventory_hostname in groups.web"
      ignore_errors: true
      changed_when: false
      delegate_to: localhost
      tags:
        - c1_11
        - c1_12

    - name: "Assert if Webserver listens on port defined in the variable webport"
      assert:
        that:
          - "'Hello from {}!'.format(hostname) in (web_server_listen.content)"
        success_msg: "Webserver are listening on port  {{ webport }} and contain their hostname in the response"
        fail_msg: "The response of the webserver does not contain 'Hello from {{ hostname }}'! Returned content: {{ web_server_listen.content }}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.web"
      tags:
        - c1_11

    - name: "Web: Webserver listens on port defined in the variable webport"
      debug:
        msg: |-
          {{ web_server_listen.content }}
      when: "inventory_hostname in groups.web"
      tags:
        - c1_11

    - pause:
        prompt: "Please mark now aspect - Web: Webserver listens on port defined in the variable webport"
      tags:
        - c1_11

    - name: "Assert if Textcolor is used"
      assert:
        that:
          - "webcolor|lower in (web_server_listen.content|lower)"
        success_msg: "The correct webcolor is used"
        fail_msg: "The webcolor is not set correctly. Expected color {{ webcolor }}! Returned content: {{ web_server_listen.content }}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.web"
      tags:
        - c1_12

    - name: "Web: Textcolor is used"
      debug:
        msg: |-
          {{ web_server_listen.content }}
      when: "inventory_hostname in groups.web"
      tags:
        - c1_12

    - pause:
        prompt: "Please mark now aspect - Web: Textcolor is used"
      tags:
        - c1_12
    
    ## Web: http://intranet.applix.com is reachable
    - name: "Test if intranet.applix.com is reachable"
      ansible.builtin.uri:
        url: "http://intranet.applix.com"
        return_content: yes
      register: web_intranet_listen
      when: "inventory_hostname in groups.web"
      ignore_errors: true
      delegate_to: localhost
      changed_when: false
      tags:
        - c1_13
        - c1_17

    - name: "Web: http://intranet.applix.com is reachable"
      debug:
        msg: "{{ web_intranet_listen.content }}"
      when: "inventory_hostname in groups.web"
      tags:
        - c1_13

    - pause:
        prompt: "Please mark now aspect - Web: http://intranet.applix.com is reachable"
      tags:
        - c1_13

    ## HA: VRRP master
    - name: "Get keepalived.data - needs at least 15 secs"
      shell: "kill -USR1 $(cat /var/run/keepalived.pid);sleep 15;cat /tmp/keepalived.data"
      register: ha_keepalived_data
      when: "inventory_hostname in groups.ha"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_14
        - c1_15
        - c1_16

    - name: "Test if VRRP state is set correctly on master node"
      assert:
        that:
          - "'Wantstate = MASTER' in ha_keepalived_data.stdout"
        success_msg: "The VRRP master has been correctly set"
        fail_msg: "The VRRP master is not set correctly. Expected Wantstate = MASTER. Returned content: {{ ha_keepalived_data.stdout | regex_findall('^.*Wantstate.*$', multiline=True) }}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname == groups.ha|last"
      tags:
        - c1_14

    - name: "Test if VRRP state is set correctly on backup nodes"
      assert:
        that:
          - "'Wantstate = BACKUP' in ha_keepalived_data.stdout"
        success_msg: "The VRRP state for backup nodes has been correctly set"
        fail_msg: "The VRRP state is not set correctly for backup nodes. Expected Wantstate = BACKUP. Returned content: {{ ha_keepalived_data.stdout | regex_findall('^.*Wantstate.*$', multiline=True) }}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.ha[0:-1]"
      tags:
        - c1_14

    - name: "HA: VRRP master"
      debug:
        msg: "{{ ha_keepalived_data.stdout | regex_findall('(^.*Wantstate.*$|^.*Priority.*$)', multiline=True) }}"
      when: "inventory_hostname in groups.ha"
      tags:
        - c1_14

    - pause:
        prompt: "Please mark now aspect - HA: VRRP master"
      tags:
        - c1_14

    ## HA: Floating IP is configured
    - name: "Test if floating IP is configured"
      assert:
        that:
          - "'10.22.0.51/24' in ha_keepalived_data.stdout"
        success_msg: "The floating IP is correctly set"
        fail_msg: "The floating IP is not set correctly. Expected 10.22.0.51/24. Returned content: {{ ha_keepalived_data.stdout | regex_findall('^.*dev\\s(?:eth0|ens).*$', multiline=True)}}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.ha"
      tags:
        - c1_15

    - name: "HA: Floating IP is configured"
      debug:
        msg: "{{ ha_keepalived_data.stdout | regex_findall('^.*dev\\s(?:eth0|ens).*$', multiline=True) }}"
      when: "inventory_hostname in groups.ha"
      tags:
        - c1_15

    - pause:
        prompt: "Please mark now aspect - HA: Floating IP is configured"
      tags:
        - c1_15

    ## HA: Keepalived is secured with password authentication
    - name: "Test if password authentication is set"
      assert:
        that:
          - "'Authentication type = SIMPLE_PASSWORD' in ha_keepalived_data.stdout"
        success_msg: "Keepalived password authentication is correctly set"
        fail_msg: "Keepalived password authentication is not set correctly. Expected Authentication type = SIMPLE_PASSWORD. Returned content: {{ ha_keepalived_data.stdout | regex_findall('^.*Authentication type.*$', multiline=True)}}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.ha"
      tags:
        - c1_16

    - name: "HA: Keepalived is secured with password authentication"
      debug:
        msg: "{{ ha_keepalived_data.stdout | regex_findall('^.*Authentication type.*$', multiline=True) }}"
      when: "inventory_hostname in groups.ha"
      tags:
        - c1_16

    - pause:
        prompt: "Please mark now aspect - HA: Keepalived is secured with password authentication"
      tags:
        - c1_16

    ## HA: X-HAPROXY-HOST HTTP header (case insensitive)
    - name: "Get intranet.applix.com"
      shell:
        cmd: "curl -v http://intranet.applix.com 2>&1 | grep -i haproxy"
        warn: False
      register: web_intranet_header
      when: "inventory_hostname in groups.web"
      delegate_to: localhost
      run_once: true
      ignore_errors: true
      changed_when: false
      tags:
        - c1_17

    - name: "Test if HAPROXY header is set"
      assert:
        that:
          - "'x_haproxy_host' in web_intranet_listen"
          - "web_intranet_listen.x_haproxy_host|upper == 'APPLIX-LINUXHOST-002'"
        success_msg: "X-HAPROXY-HOST Header is correctly set"
        fail_msg: "X-HAPROXY-HOST header is not set correctly. Expected x-haproxy-host: APPLIX-LINUXHOST-002. Returned content: {{ web_intranet_listen.x_haproxy_host }}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.web"
      run_once: true
      tags:
        - c1_17

    - name: "HA: X-HAPROXY-HOST HTTP header (case insensitive)"
      debug:
        msg: "{{ web_intranet_header.stdout }}"
      when: "inventory_hostname in groups.web"
      run_once: True
      tags:
        - c1_17

    - pause:
        prompt: "Please mark now aspect - HA: X-HAPROXY-HOST HTTP header (case insensitive)"
      tags:
        - c1_17

    ## Users: User from CSV file imported
    - name: "Count user entries"
      shell: "cat /etc/passwd | wc -l" 
      register: users_imported_count
      when: "inventory_hostname in groups.linux"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_18

    - name: "Test if amount of users is higher than 50"
      assert:
        that:
          - "users_imported_count.stdout|int > 50"
        success_msg: "Users have been correctly imported"
        fail_msg: "Users have not been correctly imported. Expected count more than 50. Returned count: {{ users_imported_count.stdout }}"
        quiet: true
      ignore_errors: true
      when: "inventory_hostname in groups.linux"
      tags:
        - c1_18

    - name: "Users: Users from CSV file are imported"
      debug:
        msg: "{{ users_imported_count.stdout }}"
      when: "inventory_hostname in groups.linux"
      tags:
        - c1_18

    - pause:
        prompt: "Please mark now aspect - Users: Users from CSV file are imported"
      tags:
        - c1_18

    # Users: Password is not overwritten
    - name: "Change password of user noah on LIN1"
      shell: "echo noah:prq7mawtDa | chpasswd" 
      when: "inventory_hostname == 'LIN1'"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_19

    - name: "Running in 15 secs /data/ansible/linux/7-users.yml to validate if password won't be overwritten"
      pause:
        seconds: 15
      tags:
        - c1_19
        
- ansible.builtin.import_playbook: /data/ansible/linux/7-users.yml
  tags:
    - c1_19

- name: MARKING Part 2 - Linux
  hosts: linux,localhost
  any_errors_fatal: false
  tasks:
    # File Share: lvm volume created with defined name and size
    - name: "Get all the lvm volumes"
      shell: "lsblk"
      when: "inventory_hostname in groups.nfs"
      register: nfs_lsblk
      ignore_errors: true
      changed_when: false
      tags:
        - c1_20

    - name: "File Share: lvm volume created with defined name and size"
      debug:
        msg: "{{ nfs_lsblk.stdout }}"
      when: "inventory_hostname in groups.nfs"
      tags:
        - c1_20

    - pause:
        prompt: "Please mark now aspect - File Share: lvm volume created with defined name and size"
      tags:
        - c1_20

    # File Share: logical volume mounted to /nfs/{sharename}
    - name: "Install nfs-common Debian ISO needs to present on HOST VM!!! "
      apt:
        name: "nfs-common"
      when: "inventory_hostname in 'localhost'"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_21

    - name: "Mount the finance share"
      shell: "mkdir -p /mnt/finance ; mount -t nfs -o 'soft,timeo=15' {{ hostvars[groups.nfs[0]]['ansible_host'] }}:/nfs/finance /mnt/finance"
      when: "inventory_hostname in 'localhost'"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_21
       
    - name: "Get all the nfs shares"
      shell: "mount | grep nfs"
      when: "inventory_hostname in 'localhost'"
      register: nfs_mount
      ignore_errors: true
      changed_when: false
      tags:
        - c1_21

    - name: "File Share: logical volume mounted to /nfs/{sharename}"
      debug:
        msg: "{{ nfs_mount.stdout }}"
      when: "inventory_hostname in 'localhost'"
      tags:
        - c1_21

    - pause:
        prompt: "Please mark now aspect - File Share: logical volume mounted to /nfs/{sharename}"
      tags:
        - c1_21

    # File Share: share only accessible from HOST VM
    - name: "Install nfs-common - Debian ISO needs to present on LIN hosts!!!" 
      apt:
        name: "nfs-common"
      when: "inventory_hostname in groups.linux"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_22

    - name: "Try to mount NFS from all the LIN hosts"
      shell: "mkdir -p /mnt/finance ; !(mount -t nfs -o 'soft,timeo=15' {{ hostvars[groups.nfs[0]]['ansible_host'] }}:/nfs/finance /mnt/finance)"
      when: "inventory_hostname in groups.linux"
      register: nfs_mount_lin_fail
      ignore_errors: true
      changed_when: false
      tags:
        - c1_22

    - name: "File Share: share only accessible from HOST VM"
      debug:
        msg: |-
          "{{ nfs_mount_lin_fail.stdout }}
          {{ nfs_mount_lin_fail.stderr }}"
      when: "inventory_hostname in groups.linux"
      tags:
        - c1_22

    - pause:
        prompt: "Please mark now aspect - File Share: share only accessible from HOST VM"
      tags:
        - c1_22

    # DNS backup: systemd service exists
    - name: "Retrieve dns backup systemd service status"
      shell: "systemctl status backup_dns.service"
      when: "(inventory_hostname in groups.backup) or (inventory_hostname in groups.dns)"
      register: backup_systemd_service
      ignore_errors: true
      changed_when: false
      tags:
        - c1_23
  
    - name: "DNS backup: systemd service exists"
      debug:
        msg: "{{ backup_systemd_service.stdout }}"
      when: "(inventory_hostname in groups.backup) or (inventory_hostname in groups.dns)"
      tags:
        - c1_23

    - pause:
        prompt: "Please mark now aspect - DNS backup: systemd service exists"
      tags:
        - c1_23

    # DNS backup: systemd timer configured
    - name: "Retrieve dns backup systemd timer status"
      shell: "systemctl status backup_dns.timer"
      when: "(inventory_hostname in groups.backup) or (inventory_hostname in groups.dns)"
      register: backup_systemd_timer
      ignore_errors: true
      changed_when: false
      tags:
        - c1_24

    - name: "DNS backup: systemd timer configured"
      debug:
        msg: "{{ backup_systemd_timer.stdout }}"
      when: "(inventory_hostname in groups.backup) or (inventory_hostname in groups.dns)"
      tags:
        - c1_24

    - pause:
        prompt: "Please mark now aspect - DNS backup: systemd timer configured"
      tags:
        - c1_24

    # DNS backup: backup exists
    - name: "Trigger DNS backup"
      shell: "systemctl start backup_dns.service"
      when: "(inventory_hostname in groups.backup) or (inventory_hostname in groups.dns)"
      ignore_errors: true
      changed_when: false
      tags:
        - c1_25

    - name: "Wait 30sec until the backup has finished"
      pause:
        seconds: 30
      tags:
        - c1_25

    - name: "Unzip the latest DNS backup"
      shell: "mkdir -p /tmp/dns_backup_assess/ ; tar -C /tmp/dns_backup_assess -xzf /backups/$(ls -Art /backups/ | grep 'tar.gz' | tail -n 1) ; ls -lah /tmp/dns_backup_assess/"
      when: "inventory_hostname in groups.backup"
      register: backup_files
      ignore_errors: true
      changed_when: false
      tags:
        - c1_25

    - name: "DNS backup: backup exists"
      debug:
        msg: "{{ backup_files.stdout }}"
      when: "inventory_hostname in groups.backup"
      tags:
        - c1_25

    - pause:
        prompt: "Please mark now aspect - DNS backup: backup exists"
      tags:
        - c1_25